{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NLP_naivebayes1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mensah50/Msc-Data-Science-and-Artificial-Intelligence-/blob/main/NLP_naivebayes1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yorYSP0_76FL"
      },
      "source": [
        "text = \"hello. I am happy. Are you?\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv6SkbBP76FN",
        "outputId": "eb7d886e-016f-4bf4-899b-0750583dd64a"
      },
      "source": [
        "# libraries for: regular expressions, file I/O\n",
        "import re\n",
        "import sys\n",
        "!pip install unicodecsv\n",
        "import unicodecsv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unicodecsv\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Building wheels for collected packages: unicodecsv\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp37-none-any.whl size=10768 sha256=6961dd49b82d461aa4127fc329f41c4720695d65c3321cf14344fe42fcf3e8e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "Successfully built unicodecsv\n",
            "Installing collected packages: unicodecsv\n",
            "Successfully installed unicodecsv-0.14.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd9m2c1q76FN"
      },
      "source": [
        "def preProcess(text):\n",
        "    #print(\"original:\", text)\n",
        "    # sentence segmentation - assume already done\n",
        "    pass\n",
        "    # word tokenisation\n",
        "    # separate out words and strings of punctuation into separate white spaced words\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(])(\\w)\", r\"\\1 \\2\", text)\n",
        "    #print(\"tokenising:\", text)\n",
        "    # no other spelling normalization done for now\n",
        "    tokens = re.split(r\"\\s+\",text)\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q552G5FW76FO",
        "outputId": "d73b48ea-7306-411b-9dac-f66a2009a179"
      },
      "source": [
        "\n",
        "print(preProcess(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', '.', 'i', 'am', 'happy', '.', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A20W_8Ha76FP"
      },
      "source": [
        "# turn into feature vectors\n",
        "featureDict = {}\n",
        "def toFeatureVector(words):\n",
        "    v = {}\n",
        "    for w in words:\n",
        "        try:\n",
        "            i = featureDict[w]\n",
        "        except KeyError:\n",
        "            i = len(featureDict) + 1\n",
        "            featureDict[w] = i\n",
        "        try:\n",
        "            v[i] += (1.0/len(words))\n",
        "        except KeyError:\n",
        "            v[i] = (1.0/len(words))\n",
        "    return v"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ISwf16w76FP",
        "outputId": "475642f3-581a-4058-87b8-3951911c0364"
      },
      "source": [
        "print(toFeatureVector(preProcess(text)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0.1111111111111111, 2: 0.2222222222222222, 3: 0.1111111111111111, 4: 0.1111111111111111, 5: 0.1111111111111111, 6: 0.1111111111111111, 7: 0.1111111111111111, 8: 0.1111111111111111}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GUlBrF076FQ",
        "outputId": "ac81201c-e70a-47f8-8175-e1684133276e"
      },
      "source": [
        "print(featureDict)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'hello': 1, '.': 2, 'i': 3, 'am': 4, 'happy': 5, 'are': 6, 'you': 7, '?': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foq2WUY576FQ",
        "outputId": "ec9c78bf-1187-4ff9-ab59-c8d3467bdaaf"
      },
      "source": [
        "# load training data from external files\n",
        "trainData = []\n",
        "trainLabels = []\n",
        "with open('pos.csv', 'r') as f:\n",
        "    for line in f:\n",
        "        trainData.append(toFeatureVector(preProcess(line)))\n",
        "        trainLabels.append(1.0)\n",
        "with open('neg.csv', 'r') as f:\n",
        "    for line in f:\n",
        "        trainData.append(toFeatureVector(preProcess(line)))\n",
        "        trainLabels.append(-1.0)\n",
        "print(len(featureDict))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbs5NIpa76FQ"
      },
      "source": [
        "train_set = [(df, l) for df, l in zip(trainData, trainLabels)] "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USLbZ7oq76FR",
        "outputId": "fd405d18-34cc-4109-a18f-b313235249ab"
      },
      "source": [
        "from collections import Counter\n",
        "Counter([label for df, label in train_set])\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({-1.0: 1000, 1.0: 1000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPuADNtk76FR"
      },
      "source": [
        "# libraries for: NLP, machine learning\n",
        "import nltk "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atn_jXKL76FR"
      },
      "source": [
        "# train\n",
        "model = nltk.NaiveBayesClassifier.train(train_set)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTemARnz76FR"
      },
      "source": [
        "# predict\n",
        "def analyseSentiment(text):\n",
        "    v = toFeatureVector(preProcess(text))\n",
        "    print(v)\n",
        "    return model.classify(v)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBQl6BL576FS",
        "outputId": "82f2f0f4-ffba-4ccf-a189-b36913c66599"
      },
      "source": [
        "# sentiment analyse the example at the top of the notebook\n",
        "s = analyseSentiment(text)\n",
        "print(\"sentiment = \", s)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1: 0.1111111111111111, 2: 0.2222222222222222, 3: 0.1111111111111111, 4: 0.1111111111111111, 5: 0.1111111111111111, 6: 0.1111111111111111, 7: 0.1111111111111111, 8: 0.1111111111111111}\n",
            "sentiment =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryqDxQq676FS",
        "outputId": "eb0ede28-7678-4d57-e3fe-86a28e8794a7"
      },
      "source": [
        "# See if we can make it output the negative label (-1)\n",
        "analyseSentiment(\"oh dear oh dear :(\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{375: 0.4, 1984: 0.4, 5371: 0.2}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    }
  ]
}