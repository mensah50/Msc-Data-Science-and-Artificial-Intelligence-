{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "NLP_dict2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mensah50/Msc-Data-Science-and-Artificial-Intelligence-/blob/main/NLP_dict2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDtDwFb-ABUb"
      },
      "source": [
        "text = \"hello I am happy. Are you?\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcKHcvr5ABUd",
        "outputId": "57534014-deb4-46e4-a412-f212198a54c7"
      },
      "source": [
        "# libraries for: regular expressions, file I/O\n",
        "import re\n",
        "import sys\n",
        "!pip install unicodecsv\n",
        "import unicodecsv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unicodecsv\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/a4/691ab63b17505a26096608cc309960b5a6bdf39e4ba1a793d5f9b1a53270/unicodecsv-0.14.1.tar.gz\n",
            "Building wheels for collected packages: unicodecsv\n",
            "  Building wheel for unicodecsv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unicodecsv: filename=unicodecsv-0.14.1-cp37-none-any.whl size=10768 sha256=2b433e161fc9db2bcefd60d2c7a020b8e3b8341f064a8d1afb43f7fb1f7872a4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/09/e9/e800279c98a0a8c94543f3de6c8a562f60e51363ed26e71283\n",
            "Successfully built unicodecsv\n",
            "Installing collected packages: unicodecsv\n",
            "Successfully installed unicodecsv-0.14.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRBz8GSrABUd"
      },
      "source": [
        "def preProcess(text):\n",
        "    print(\"original:\", text)\n",
        "    # sentence segmentation - assume already done\n",
        "    pass\n",
        "    # word tokenisation\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text)\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(])(\\w)\", r\"\\1 \\2\", text)\n",
        "    print(\"tokenising:\", text)\n",
        "    tokens = re.split(r\"\\s+\",text)\n",
        "    # normalisation\n",
        "    text = re.sub(r\"(\\S)\\1\\1+\",r\"\\1\\1\\1\", text)\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    return tokens"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po8YIlX4ABUe",
        "outputId": "08b76998-34e7-4a50-f922-49db0ce34d4a"
      },
      "source": [
        "print(preProcess(text))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original: hello I am happy. Are you?\n",
            "tokenising: hello I am happy . Are you ?\n",
            "['hello', 'i', 'am', 'happy', '.', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4nkk4W0ABUf",
        "outputId": "fb4e2be7-d4f9-44a7-de2c-57b483e022be"
      },
      "source": [
        "# load an external dictionary\n",
        "sentimentDict = {}\n",
        "with open('sentiment.csv', 'rb') as f:\n",
        "    reader = unicodecsv.reader(f, encoding='utf-8')\n",
        "    for line in reader:\n",
        "        sentimentDict[line[0]] = float(line[1])\n",
        "print(sentimentDict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'happy': 1.0, 'sad': -1.0, 'good': 1.0, 'bad': -1.0, 'angry': -2.0, 'ecstatic': 2.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRYRvfKyABUf"
      },
      "source": [
        "def getSentiment(word):\n",
        "    try:\n",
        "        return sentimentDict[word]\n",
        "    except KeyError:\n",
        "        return 0.0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af9DcJYIABUf"
      },
      "source": [
        "def analyseSentiment(text):\n",
        "    words = preProcess(text)\n",
        "    print(\"words:\", words)\n",
        "    scores = [getSentiment(w) for w in words]\n",
        "    print(\"scores\", scores)\n",
        "    return sum(scores)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erFeF0JkABUg",
        "outputId": "1e3753cc-4eed-4d12-c465-5c402ad87362"
      },
      "source": [
        "s = analyseSentiment(text)\n",
        "print(\"sentiment = \", s)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original: hello I am happy. Are you?\n",
            "tokenising: hello I am happy . Are you ?\n",
            "words: ['hello', 'i', 'am', 'happy', '.', 'are', 'you', '?']\n",
            "scores [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "sentiment =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-6m-3wPABUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rF3ynkgABUg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}